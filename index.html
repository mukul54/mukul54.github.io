<!DOCTYPE HTML>
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Mukul Ranjan</title>
    <meta name="author" content="Mukul Ranjan">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="style.css">
</head>

<body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr style="padding:0px">
            <td style="padding:0px">
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr style="padding:0px">
                        <td style="padding:2.5%;width:63%;vertical-align:middle">
                            <p class="name" style="text-align: center;">
                                Mukul Ranjan
                            </p>
                            <p>
                                I am a Master's student in Machine Learning at <a href="https://mbzuai.ac.ae" target="_blank">MBZUAI</a>, where I work with <a href="https://zhiqiangshen.com/" target="_blank">Prof. Zhiqiang Shen</a>. My research focuses on <strong>efficient machine learning systems</strong>, particularly developing alternate architectures and hardware-aware algorithms through <strong>sparsity, quantization, and hardware-software co-design</strong>. Most recently I also worked with <a href="https://dchen.ece.illinois.edu/" target="_blank">Prof. Deming Chen</a> at UIUC from Jul. 2025 to Oct. 2025. I also work on creating evaluation methodologies and benchmarks for these systems.
                            </p>
                            <p>
                                Previously, I was a Data Scientist at <a href="https://www.meesho.com/" target="_blank">Meesho</a>, where I built personalized ranking systems, and an AI Research Scientist at <a href="https://www.qure.ai/" target="_blank">Qure.ai</a>, developing automated stroke severity assessment systems deployed in hospitals worldwide.
                            </p>
                            <p>
                                I hold a B.Tech. in Electronics and Communication Engineering from <a href="https://www.iitg.ac.in/" target="_blank">IIT Guwahati</a>.
                            </p>
                            <p style="text-align:center">
                                <a href="mailto:mukulranjan0@gmail.com">Email</a> &nbsp;/&nbsp;
                                <a href="#">CV</a> &nbsp;/&nbsp;
                                <a href="https://scholar.google.com/citations?hl=en&user=fFBR0j0AAAAJ&view_op=list_works&sortby=pubdate" target="_blank">Scholar</a> &nbsp;/&nbsp;
                                <a href="https://github.com/mukul54" target="_blank">Github</a> &nbsp;/&nbsp;
                                <a href="https://linkedin.com/in/mr54" target="_blank">LinkedIn</a> &nbsp;/&nbsp;
                                <a href="https://medium.com/@mukulranjan">Medium</a>
                                <!-- <a href="ml-blogs.html">Blog</a> -->
                            </p>
                        </td>
                        <td style="padding:2.5%;width:37%;max-width:37%">
                            <a href="profile-photos/profile.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="profile-photos/profile.jpg"></a>
                        </td>
                    </tr>
                </tbody></table>

                <!-- Research Interests
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <h2>Research Interests</h2>
                            <p>
                                I'm interested in efficient machine learning, computer vision, and natural language processing. My research focuses on making AI models faster, smaller, and more accessible through pruning, quantization, and novel architectures.
                            </p>
                        </td>
                    </tr>
                </tbody></table> -->

                <!-- News -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <h2>News</h2>
                        </td>
                    </tr>
                </tbody></table>
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:8px 20px;width:20%;vertical-align:middle"><strong>Oct 2025</strong></td>
                        <td style="padding:8px 20px;width:80%;vertical-align:middle">Elastic-Cache for Diffusion LLMs released</td>
                    </tr>
                    <tr>
                        <td style="padding:8px 20px;width:20%;vertical-align:middle"><strong>May 2025</strong></td>
                        <td style="padding:8px 20px;width:80%;vertical-align:middle">SpookyBench paper on temporal reasoning in VLMs released</td>
                    </tr>
                    <tr>
                        <td style="padding:8px 20px;width:20%;vertical-align:middle"><strong>Feb 2025</strong></td>
                        <td style="padding:8px 20px;width:80%;vertical-align:middle">KITAB-Bench accepted at ACL 2025!</td>
                    </tr>
                    <tr>
                        <td style="padding:8px 20px;width:20%;vertical-align:middle"><strong>Oct 2024</strong></td>
                        <td style="padding:8px 20px;width:80%;vertical-align:middle">Won 1st place at GITEX DGE Elite Hackathon for Cybersecurity</td>
                    </tr>
                    <tr>
                        <td style="padding:8px 20px;width:20%;vertical-align:middle"><strong>Aug 2024</strong></td>
                        <td style="padding:8px 20px;width:80%;vertical-align:middle">Started MS in Machine Learning at MBZUAI</td>
                    </tr>
                </tbody></table>

                <!-- Publications Section Header -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:20px;width:100%;vertical-align:middle">
                            <h2>Publications</h2>
                            <p>Representative papers are <span class="highlight">highlighted</span>.</p>
                        </td>
                    </tr>
                </tbody></table>

                <!-- Publications List -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                    <!-- Publication 1 - Elastic-Cache (highlighted) -->
                    <tr bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/elastic-cache.png" alt="Elastic-Cache" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.arxiv.org/abs/2510.14973">
                                <span class="papertitle">Attention Is All You Need for KV Cache in Diffusion LLMs</span>
                            </a>
                            <br>
                            Quan Nguyen-Tri*, <strong>Mukul Ranjan*</strong>, and Zhiqiang Shen
                            <br>
                            <em>Under Review</em>, 2025
                            <br>
                            <a href="https://www.arxiv.org/abs/2510.14973">arXiv</a>
                            /
                            <a href="https://github.com/VILA-Lab/Elastic-Cache">code</a>
                            /
                            <a href="https://vila-lab.github.io/elastic-cache-webpage/">project page</a>
                            <p></p>
                            <p>
                                Elastic-Cache is a training-free framework that accelerates Diffusion LLMs up to 45.1x with higher accuracy by adaptively refreshing the KV cache.
                            </p>
                        </td>
                    </tr>

                    <!-- Publication 2 - SpookyBench (highlighted) -->
                    <tr bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/spookybench.png" alt="SpookyBench" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2505.24867">
                                <span class="papertitle">Time Blindness: Why Video-Language Models Can't See What Humans Can?</span>
                            </a>
                            <br>
                            Ujjwal Upadhyay*, <strong>Mukul Ranjan*</strong>, Zhiqiang Shen, and Mohamed Elhoseiny
                            <br>
                            <em>Under Review</em>, 2025
                            <br>
                            <a href="https://arxiv.org/abs/2505.24867">arXiv</a>
                            /
                            <a href="https://github.com/TimeBlindness/time-blindness">code</a>
                            /
                            <a href="https://timeblindness.github.io/">project page</a>
                            <p></p>
                            <p>
                                SpookyBench reveals that patterns in temporal noise that humans recognize with 98% accuracy, state-of-the-art VLMs fails completely achieving 0%.
                            </p>
                        </td>
                    </tr>

                    
                    <!-- Publication 3 - Mobile-MMLU -->
                    <tr bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/mobile-mmlu.png" alt="Mobile-MMLU" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2503.20786">
                                <span class="papertitle">Mobile-MMLU: A Mobile Intelligence Language Understanding Benchmark</span>
                            </a>
                            <br>
                            Sondos Mahmoud Bsharat*, <strong>Mukul Ranjan*</strong>, Aidar Myrzakhan*, et al.
                            <br>
                            <em>Under Review</em>, 2025
                            <br>
                            <a href="https://arxiv.org/abs/2503.20786">arXiv</a>
                            /
                            <a href="https://huggingface.co/datasets/MBZUAI-LLM/Mobile-MMLU">dataset</a>
                            /
                            <a href="https://vila-lab.github.io/Mobile_MMLU/">project page</a>
                            <p></p>
                            <p>
                                Mobile-MMLU is a benchmark with with 16,000+ questions across 80 mobile-related fields to evaluate LLM performance under real-world constraints.
                            </p>
                        </td>
                    </tr>

                    <!-- Publication 4 - GBLM-Pruner (highlighted) -->
                    <tr bgcolor="#ffffd0">
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/gblm-pruner.png" alt="GBLM-Pruner" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <span class="papertitle">Beyond Size: How Gradients Shape Pruning Decisions in Large Language Models</span>
                            <br>
                            Rocktim Jyoti Das*, <strong>Mukul Ranjan*</strong>, Mingjie Sun*, Liqun Ma, and Zhiqiang Shen
                            <br>
                            <em>Under Review</em>
                            <br>
                            <a href="#">arXiv (coming soon)</a>
                            /
                            <a href="#">code</a>
                            <p></p>
                            <p>
                                GBLM-Pruner is a gradient-based pruning method that is extremeley faster than weight-update methods like SparseGPT.
                            </p>
                        </td>
                    </tr>

                    <!-- Publication 5 - GLoRA -->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/glora.png" alt="GLoRA" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <span class="papertitle">One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning</span>
                            <br>
                            Arnav Chavan*, <strong>Mukul Ranjan*</strong>, Zhuang Liu, Deepak Gupta, Eric Xing, and Zhiqiang Shen
                            <br>
                            <em>Pending Submission for IEEE TPAMI</em>, 2025
                            <br>
                            <a href="#">arXiv (coming soon)</a>
                            /
                            <a href="#">code</a>
                            <p></p>
                            <p>
                                GLoRA is a unified PEFT framework achieving state-of-the-art accuracy with zero inference overhead through structural re-parameterization.
                            </p>
                        </td>
                    </tr>

                    <!-- Publication 6 - KITAB-Bench -->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/kitab-bench.png" alt="KITAB-Bench" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2502.14949">
                                <span class="papertitle">KITAB-Bench: A Comprehensive Multi-Domain Arabic OCR Benchmark</span>
                            </a>
                            <br>
                            Ahmed Heakl*, Muhammad Abdullah Sohail*, <strong>Mukul Ranjan*</strong>, et al.
                            <br>
                            <em>ACL 2025 (Findings)</em>, 2025
                            <br>
                            <a href="https://arxiv.org/abs/2502.14949">arXiv</a>
                            /
                            <a href="#">dataset</a>
                            <p></p>
                            <p>
                                KITAB-Bench has 8,809 samples across 9 domains. It reveals that vision-language models outperform traditional OCR by 60%.
                            </p>
                        </td>
                    </tr>

                    <!-- Publication 7 - Deep-ASPECTS -->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/deep-aspects.png" alt="Deep-ASPECTS" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://arxiv.org/abs/2203.03622">
                                <span class="papertitle">Deep-ASPECTS: A Segmentation-Assisted Model for Stroke Severity Measurement</span>
                            </a>
                            <br>
                            Ujjwal Upadhyay, <strong>Mukul Ranjan</strong>, et al.
                            <br>
                            <em>ECCV</em>, 2022
                            <br>
                            <a href="https://arxiv.org/abs/2203.03622">arXiv</a>
                            <p></p>
                            <p>
                                Deep-ASPECTS is an automated ASPECT scoring system achieving radiologist-level performance, now deployed in hospitals worldwide.
                            </p>
                        </td>
                    </tr>

                    <!-- Publication 8 - Sanskrit -->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/sanskrit.png" alt="Sanskrit Translation" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://www.sciencedirect.com/science/article/pii/S2949719123000225">
                                <span class="papertitle">An Evaluation of Google Translate for Sanskrit to English Translation</span>
                            </a>
                            <br>
                            Akshat Shukla, Chaarvi Bansal, Sushrut Badhe, <strong>Mukul Ranjan</strong>, and Rohitash Chandra
                            <br>
                            <em>Natural Language Processing Journal</em>, 2023
                            <br>
                            <a href="https://www.sciencedirect.com/science/article/pii/S2949719123000225">paper</a>
                        </td>
                    </tr>

                    <!-- Publication 9 - Hindu Philosophy -->
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <img src="papers/hindu-philosophy.png" alt="Hindu Philosophy AI" width="160">
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0273476">
                                <span class="papertitle">Artificial Intelligence for Topic Modelling in Hindu Philosophy</span>
                            </a>
                            <br>
                            Rohitash Chandra* and <strong>Mukul Ranjan*</strong>
                            <br>
                            <em>PLOS ONE</em>, 2022
                            <br>
                            <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0273476">paper</a>
                        </td>
                    </tr>

                </tbody></table>

                <!-- Footer -->
                <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                    <tr>
                        <td style="padding:20px">
                            <p style="text-align:center;font-size:12px;">
                                Last updated: January 2026
                                <br>
                                Â© 2026 Mukul Ranjan. Design inspired by <a href="https://jonbarron.info/">Jon Barron</a>.
                            </p>
                        </td>
                    </tr>
                </tbody></table>

            </td>
        </tr>
    </tbody></table>
</body>
</html>
